{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras.utils \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    \"\"\"\n",
    "    #Argument: \n",
    "        img: shape(width, heigh, channel)\n",
    "    #return:\n",
    "        img normalize\n",
    "    \"\"\"\n",
    "    width = X.shape[0]\n",
    "    heigh = X.shape[1]\n",
    "    channel = X.shape[2]\n",
    "    for i in range(0,width):\n",
    "        image[i,:,:] = image[i,:,:]/np.max(image[i,:,:], axis = 0) \n",
    "    return image\n",
    "def normalize_standard(X):\n",
    "    \"\"\"\n",
    "    #Argument: \n",
    "        X: shape(num, width, heigh, channel)\n",
    "    #return:\n",
    "        X normalize\n",
    "    \"\"\"\n",
    "#     caculate mean\n",
    "    num_img = X.shape[0]\n",
    "    width = X.shape[1]\n",
    "    heigh = X.shape[2]\n",
    "    channel = X.shape[3]\n",
    "    total_value_pixel = np.sum(X, axis = 3) #shape (num,width, heigh)\n",
    "    total_value_pixel = np.sum(X, axis = 0) #shape (width, heigh)\n",
    "    mean = total_value_pixel/(channel * num_img)\n",
    "    \n",
    "#     caculate standard deviation\n",
    "    if channel == 3:\n",
    "        channel1 = np.square(X[:,:,:,0] - mean)\n",
    "        channel2 = np.square(X[:,:,:,1] - mean)\n",
    "        channel3 = np.square(X[:,:,:,2] - mean)\n",
    "        total = channel1 + channel2 + channel3\n",
    "    elif channel == 1:\n",
    "        total = X[:,:,:,0] - mean\n",
    "    \n",
    "    std = math.sqrt(total/(channel*num_img))\n",
    "    \n",
    "    x0 = (X[:,:,:,0] - mean)/std\n",
    "    x1 = (X[:,:,:,1] - mean)/std\n",
    "    x2 = (X[:,:,:,2] - mean)/std\n",
    "    \n",
    "    return np.concatenate((x0,x1,x2),axis = 0)\n",
    "\n",
    "def read_data_info_from_csv(csv_path,is_crop):\n",
    "    \"\"\"\n",
    "    #Argument:\n",
    "        csv_path: path of file csv that container information of data per class \n",
    "        (ex: file name, size, roi.x, roi.y, class id)\n",
    "    #Return:\n",
    "        images, labels, number image of class\n",
    "        type: list\n",
    "    \"\"\"\n",
    "    print(csv_path)\n",
    "    images =[]\n",
    "    labels=[]\n",
    "    data_info_csv = pd.read_csv(csv_path, sep=';')\n",
    "    num_img_of_class = len(data_info_csv[\"Filename\"])\n",
    "    parent_dir_name =os.path.dirname(csv_path)\n",
    "    for i in range(num_img_of_class):\n",
    "        #read information of csv file\n",
    "        img_name = data_info_csv[\"Filename\"][i]\n",
    "        roi_x1=data_info_csv['Roi.X1'][i]\n",
    "        roi_y1 = data_info_csv['Roi.Y1'][i]\n",
    "        roi_x2 =data_info_csv['Roi.X2'][i]\n",
    "        roi_y2 =data_info_csv['Roi.Y2'][i]\n",
    "        label = data_info_csv['ClassId'][i]\n",
    "        img_path = os.path.join(parent_dir_name,img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = normalize(image)\n",
    "        if is_crop:\n",
    "             image = image[roi_y1:roi_y2,roi_x1:roi_x2,:]\n",
    "        image = cv2.resize(image,(32,32))\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    \n",
    "    images = np.asarray(images)\n",
    "    images = normalize_standard(images)\n",
    "    return  images,labels,num_img_of_class\n",
    "\n",
    "def read_data(data_dir,is_crop):\n",
    "    \"\"\"\n",
    "    #argument:\n",
    "        data_dir: path of directory\n",
    "    #return:\n",
    "        images, labels, number of sample\n",
    "    \"\"\"\n",
    "     # Get all subdirectories of data_dir. Each represents a label.\n",
    "    directories = [d for d in os.listdir(data_dir) \n",
    "                   if os.path.isdir(os.path.join(data_dir, d))]\n",
    "     # Loop through the label directories and collect the data in\n",
    "    # two lists, labels and images.\n",
    "    print(f\"directories: {directories}\")\n",
    "    labels = []\n",
    "    images = []\n",
    "    num_sample =0;\n",
    "    num_classes =0;\n",
    "    total_num_img =0\n",
    "    for index,d in enumerate(directories):\n",
    "        label_dir = os.path.join(data_dir, d)\n",
    "        #find path data information in csv file   \n",
    "        path_info_data_csv = [os.path.join(label_dir, f)  for f in os.listdir(label_dir) if f.endswith(\".csv\")]\n",
    "        \n",
    "        for fn_csv in path_info_data_csv:      \n",
    "            imgs, lbs,num_img_of_class = read_data_info_from_csv(fn_csv,is_crop)\n",
    "            total_num_img = total_num_img+num_img_of_class;\n",
    "            \n",
    "            images.extend(imgs)\n",
    "            labels.extend(lbs)\n",
    "            \n",
    "            print(f\"index_name: {index}, directory : {d}, total number of image: {num_img_of_class}\")\n",
    "        num_classes=num_classes+1; \n",
    "    print(f\"total_num_img: {total_num_img}\")\n",
    "    \n",
    "    #read label's name\n",
    " \n",
    "\n",
    "    images= np.asarray(images)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    return images, labels,num_classes\n",
    "##test read data train and test\n",
    "# images,labels,num_classes = read_data(r'..\\data\\train\\Images')\n",
    "# images,labels,num_classes = read_data_info_from_csv(r'..\\data\\test\\Images\\GT-online_test.csv')\n",
    "# print(np.asarray(images).shape)\n",
    "\n",
    "def get_labels_name():\n",
    "    \"\"\"\n",
    "    get labels' name\n",
    "    \"\"\"\n",
    "    labels_name =[]\n",
    "    sign_nanme_csv = pd.read_csv(r\"..\\sign_name.csv\",delimiter=';')\n",
    "    labels_name = sign_nanme_csv['SignName']\n",
    "    labels_name=np.asarray(labels_name)\n",
    "    return labels_name\n",
    "\n",
    "def load_data(pickle_fn,is_crop=False):\n",
    "    \"\"\"\n",
    "    #Argument\n",
    "        pickle_fn: name of data file\n",
    "    #return:\n",
    "        data{\n",
    "            'ims':images, \n",
    "            'lbs':labels,\n",
    "            'num_classes':num_classes,\n",
    "            'lbs_name':labels_name\n",
    "        }\n",
    "    \n",
    "    check if pickle_fn is exsist => read file \n",
    "    else: read data from direction \"..\\data\\train\\GTSRB\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if not os.path.isfile(pickle_fn):\n",
    "        print(\"create pickle file\")\n",
    "        data_train_dir=r\"..\\data\\train\\GTSRB\"\n",
    "        images, labels,num_classes = read_data(data_train_dir,is_crop)\n",
    "        labels_name = get_labels_name()\n",
    "        mydata = {'ims':images, 'lbs':labels, 'num_class':num_classes,'lbs_name':labels_name}\n",
    "        pickle.dump(mydata, open(pickle_fn, 'wb'))\n",
    "    else:\n",
    "        print(\"load pickle.....\")\n",
    "        mydata= pickle.load(open(pickle_fn,'rb'))\n",
    "        images = mydata['ims']\n",
    "        labels = mydata['lbs']\n",
    "        num_classes = mydata['num_class']\n",
    "        labels_name = mydata['lbs_name']\n",
    "    return images, labels, num_classes,labels_name\n",
    "def print_data_info():\n",
    "    print(f\"len image: {len(images)}\")\n",
    "    print(f'images.shape: {images.shape}')\n",
    "    print(f\"labels: {labels}\")\n",
    "    print(f\"labels shape: {labels.shape}\")\n",
    "\n",
    "    \n",
    "# pickle_fn=r\"..\\data_compressed\\data_no_crop_30_09.p\"\n",
    "# images,labels,num_classes,labes_name=load_data(pickle_fn,is_crop=False)\n",
    "# print_data_info()\n",
    "# print(np.max(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_onehot(labels,num_classes):\n",
    "    labels_onehot= keras.utils.to_categorical(labels,num_classes)\n",
    "    return labels_onehot\n",
    "\n",
    "def convert_onehot_numpy(labels,num_classes):\n",
    "    labels_onehot = np.eye(num_classes)[labels]\n",
    "    return labels_onehot\n",
    "\n",
    "def split_data(X,y, valid_size=0.2,shuffle=True):\n",
    "    x_train, x_valid,y_train,y_valid = train_test_split(x,y,test_size =valid_size,shuffle =shuffle)\n",
    "    return  x_train, x_valid,y_train,y_valid\n",
    "\n",
    "# transform image\n",
    "import warnings \n",
    "from skimage.transform import rotate,ProjectiveTransform, warp\n",
    "from skimage import exposure\n",
    "\n",
    "def _convert_shape_to_4_dementions(image):\n",
    "    \"\"\"\n",
    "    change shape of image to 4 dementions to caculate transform and plot (num_img,img_size,img_size,channel)\n",
    "    \"\"\"\n",
    "    shape_img = image.shape\n",
    "    len_shape_img = len(shape_img)\n",
    "    # shape image is (img_size,img_size,channel=3 or1)  or gray image(num_img,img_size,img_size)\n",
    "    if len_shape_img==3:\n",
    "        if image.shape[2] == 3 or image.shape[2] == 1:\n",
    "            image = image.reshape(-1,image.shape[0],image.shape[1],image.shape[2])\n",
    "        else:\n",
    "            image=image.reshape(image.shape +(1,))\n",
    "            \n",
    "    return image\n",
    "    \n",
    "def transform_rotate(X, intensity=0.75):\n",
    "    \"\"\"\n",
    "    #Arguments\n",
    "        X: images\n",
    "        intensity: cuong do, the value must be (0,1]\n",
    "    #return:\n",
    "        image is roated with intensity\n",
    "    \"\"\"\n",
    "    X=_convert_shape_to_4_dementions(X)\n",
    "    \n",
    "    X_rotate =[]\n",
    "    for i in range(X.shape[0]):\n",
    "        delta = 25. * intensity # scale using augmentation intensity\n",
    "        x = rotate(X[i], np.random.uniform(-delta, delta), mode = 'edge')\n",
    "        X_rotate.append(x)\n",
    "    \n",
    "    X_rotate= np.asarray(X_rotate)\n",
    "    return X_rotate\n",
    "\n",
    "def transform_projection(X, intensity = 0.75):\n",
    "    \"\"\"\n",
    "    convert image to image distortion\n",
    "    X: image data\n",
    "    intensity: cuong do bop meo image, value must be (0,1]\n",
    "    \n",
    "    return: array image is distorted with same shape\n",
    "    \n",
    "    for example: http://scikit-image.org/docs/dev/auto_examples/xx_applications/plot_geometric.html\n",
    "    \"\"\"\n",
    "    # trục tọa độ: gốc (0,0) là góc trên bên trái\n",
    "    \n",
    "    X=_convert_shape_to_4_dementions(X)\n",
    "    image_size = X.shape[1]\n",
    "    d = image_size *0.25*intensity\n",
    "    x_pre = []\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        tl_top = np.random.uniform(-d, d)     # Top left corner, top margin\n",
    "        tl_left = np.random.uniform(-d, d)    # Top left corner, left margin\n",
    "        bl_bottom = np.random.uniform(-d, d)  # Bottom left corner, bottom margin\n",
    "        bl_left = np.random.uniform(-d, d)    # Bottom left corner, left margin\n",
    "        tr_top = np.random.uniform(-d, d)     # Top right corner, top margin\n",
    "        tr_right = np.random.uniform(-d, d)   # Top right corner, right margin\n",
    "        br_bottom = np.random.uniform(-d, d)  # Bottom right corner, bottom margin\n",
    "        br_right = np.random.uniform(-d, d)   # Bottom right corner, right margin\n",
    "\n",
    "        src = np.array([[0,0],[0,image_size],[image_size,image_size],[image_size,0]])\n",
    "        \n",
    "        dst = np.array([[tl_left,tl_top], \n",
    "                       [bl_left,image_size-bl_bottom],\n",
    "                       [image_size-br_right,image_size-br_bottom],\n",
    "                       [image_size-tr_right,tr_top]])\n",
    "        \n",
    "        transform = ProjectiveTransform()\n",
    "        transform.estimate(src=src,dst=dst)\n",
    "        \n",
    "        #using mode='edge' to remove the black space in image after use transform  \n",
    "        img_preprocess = warp(X[i], transform, output_shape=(image_size, image_size), order = 1, mode = 'edge')\n",
    "        x_pre.append(img_preprocess)\n",
    "    \n",
    "    x_pre = np.asarray(x_pre)\n",
    "    return x_pre\n",
    "\n",
    "\n",
    "def transform_brightness(images):\n",
    "    images = _convert_shape_to_4_dementions(images)\n",
    "   \n",
    "    new_images=[]\n",
    "    for img in images:\n",
    "        ratio = np.random.uniform(low=0.4,high=4.,size=1)\n",
    "        img_1 = exposure.adjust_gamma(img,ratio)\n",
    "        new_images.append(img_1)\n",
    "        \n",
    "    new_images = np.asarray(new_images)\n",
    "    return new_images\n",
    "\n",
    "def preprocess_dataset(X, y = None,is_shuffle=False):\n",
    "    \"\"\"\n",
    "    param X: images input\n",
    "    param y: labels, the dimention is 1\n",
    "    \n",
    "    return:\n",
    "        images with channel is 1 and the dimetion is (num_img,img_size,img_size,1)\n",
    "        the value of pixel is normalize\n",
    "    \n",
    "    image will be processed before use as input of model\n",
    "    \n",
    "    \"\"\"\n",
    "    #Convert to grayscale, e.g. single Y channel\n",
    "    # cong thuc : Y =0.299R+0.587G+0.114B, U = -0.147R-0.289G+0.436B, V=0.615R-0.515G-0.100B\n",
    "    # YUV channle\n",
    "    X = 0.299 * X[:, :, :, 0] + 0.587 * X[:, :, :, 1] + 0.114 * X[:, :, :, 2]\n",
    "\n",
    "    #Scale features to be in [0, 1]\n",
    "   \n",
    "      \n",
    "    # Apply localized histogram localization  \n",
    "    for i in range(X.shape[0]):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            if np.max(X[i])>1:\n",
    "                X[i] = (X[i] / 255.).astype(np.float32)\n",
    "            X[i] = exposure.equalize_adapthist(X[i])\n",
    "        \n",
    "    if is_shuffle:  \n",
    "        # Shuffle the data\n",
    "        X, y = shuffle(X, y)\n",
    "\n",
    "    # Add a single grayscale channel\n",
    "    X = X.reshape(X.shape + (1,)) \n",
    "    return X, y\n",
    "\n",
    "def preprocess_input_gray_norm(images):\n",
    "    img_intput_model = []\n",
    "    \n",
    "    num_img = images.shape[0]\n",
    "    for i in range(num_img):\n",
    "        img = images[i]\n",
    "        red_channel =img[:,:,0]\n",
    "        green_channel = img[:,:,1]\n",
    "        blue_channel = img[:,:,2]\n",
    "        \n",
    "        #convert image to gray by red, greeen, blue channel\n",
    "        # can't use cv2.cvtColor because the type's pixcel's value are not int8 (maybe [0,1],float32)\n",
    "        gray_img = 0.2989 * red_channel + 0.5870 * green_channel + 0.1140 * blue_channel\n",
    "        \n",
    "        if (np.max(gray_img)>1):\n",
    "            gray_img = gray_img/255.\n",
    "        img_intput_model.append(gray_img)\n",
    "        \n",
    "    img_intput_model = np.asarray(img_intput_model)\n",
    "    img_intput_model = normalize_standard(img_intput_model)\n",
    "    img_intput_model = img_intput_model.astype(np.float32)\n",
    "    #convert input to 4 dimention\n",
    "    img_intput_model = img_intput_model.reshape(img_intput_model.shape +(1,))\n",
    "    return img_intput_model\n",
    "\n",
    "def crop_image(images):\n",
    "    images = _convert_shape_to_4_dementions(images)\n",
    "   \n",
    "    new_images=[]\n",
    "    crop_size = np.random.randint(5,25)\n",
    "    for img in images:\n",
    "        img = cv2.resize(img,(32,32))\n",
    "#         print(f\"crop_image: shape img: {img.shape}\")\n",
    "        red_channel =img[:,:,0]\n",
    "        green_channel = img[:,:,1]\n",
    "        blue_channel = img[:,:,2]\n",
    "        \n",
    "        #convert image to gray by red, greeen, blue channel\n",
    "        # can't use cv2.cvtColor because the type's pixcel's value are not int8 (maybe [0,1],float32)\n",
    "        img = 0.2989 * red_channel + 0.5870 * green_channel + 0.1140 * blue_channel\n",
    "        \n",
    "        img = np.reshape(img, (32,32,1))\n",
    "        if crop_size > 15:\n",
    "            img1 = img[0:crop_size,0:crop_size,:]\n",
    "        else:\n",
    "            img1 = img[crop_size:32,crop_size:32,:]\n",
    "        img1 = cv2.resize(img1,(32,32))\n",
    "        new_images.append(img1)\n",
    "\n",
    "    new_images = np.asarray(new_images)\n",
    "    return new_images\n",
    "\n",
    "\"\"\"plot image\"\"\"\n",
    "\n",
    "def plot_histogram_contrast(img):\n",
    "    \"\"\"\n",
    "    the different between low and high  contrast (tuong phan)\n",
    "    show the chart of y, u channel\n",
    "    y's chanel value is spreaded => high\n",
    "    \"\"\"\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_RGB2YUV)\n",
    "    y,u,v = [img[:,:,i] for i in range(3)]\n",
    "    u=u.reshape(-1)\n",
    "    y=y.reshape(-1)\n",
    "    fig,axes = plt.subplots(1,2)\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    axes[0].hist(u,256 ,range=(0, 256), fc='k', ec='k')\n",
    "    axes[0].set_title(\"low contrast\")\n",
    "    \n",
    "    axes[1].hist(y,256 ,range=(0, 256), fc='k', ec='k')\n",
    "    axes[1].set_title(\"high contrast\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_image(images,rows,cols):\n",
    "    images=_convert_shape_to_4_dementions(images)\n",
    "    \n",
    "    num_img = images.shape[0]\n",
    "#   \n",
    "#     print(\"plto iamge: images shape: \", images.shape)\n",
    "    if num_img < (rows*cols):\n",
    "        rows= math.ceil(math.sqrt(num_img))\n",
    "        cols =math.ceil(math.sqrt(num_img))\n",
    "    \n",
    "    #check if image in images is gray image, must reshape image to (num_img,img_size,img_size) to plot img \n",
    "    if (images.shape[-1]==1):\n",
    "        img_height = images.shape[1]\n",
    "        img_width = images.shape[2]\n",
    "        images=images.reshape(num_img,img_height,img_width)\n",
    "    \n",
    "    fig,axes = plt.subplots(nrows=rows,ncols=cols,figsize=(20,20),clear=True)\n",
    "    plt.subplots_adjust(hspace=0.5,wspace =0.5)\n",
    "    \n",
    "    axes = np.array(axes)\n",
    "#     print(f\"fig: {fig}, ax: {axes.shape}\")\n",
    "    for i,ax in enumerate(axes.reshape(-1)):\n",
    "        #convert bgr to rgb\n",
    "#         index = np.random.randint(0,num_img)\n",
    "        index =i\n",
    "#         print(\"num_img: \",num_img)\n",
    "#         print(\"index; \",index)\n",
    "        if index >= num_img:\n",
    "#             print(\"out of num_img\")\n",
    "            break;\n",
    "        #check if img is gray iamge\n",
    "        if images.shape[-1]!=3:\n",
    "#             print(f\"images shape: {images.shape} , index: {index}\")\n",
    "            image = images[index]\n",
    "#             print(\"img shape: \", image.shape)\n",
    "            ax.imshow(image, cmap='gray')\n",
    "        else:\n",
    "#             print(\"plt image: images shape: \",images.shape)\n",
    "#             print('index: ',index)\n",
    "            image = images[index]\n",
    "            image = image[:,:,::-1] #convert bgr to rgb to show on matplot\n",
    "            ax.imshow(image) #,aspect='auto'\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_compare_transform_data(X):\n",
    "    import math\n",
    "    X= _convert_shape_to_4_dementions(X)\n",
    "    num_img = X.shape[0]\n",
    "    if (num_img >10):\n",
    "        num_img=10\n",
    "   \n",
    "    #compare between preprocess_img, original image, gray image\n",
    "    print(\"origin image\")\n",
    "    plot_image(X,1,num_img)\n",
    "   \n",
    "    #gray\n",
    "    print(\"gray image \")\n",
    "    x_gray=[]\n",
    "    for ind,img in enumerate(X):\n",
    "        x = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        x_gray.append(x)\n",
    "    x_gray = np.asarray(x_gray)\n",
    "    \n",
    "    print(f\"x_gray shape:  nmax: {np.max(x_gray[0])}, nmin: {np.min(x_gray[0])}\")\n",
    "    plot_image(x_gray,1,num_img)\n",
    "    \n",
    "    print(\"pre process iamge\")\n",
    "    X_preprocess,y= preprocess_dataset(X)\n",
    "    plot_image(X_preprocess,1,num_img)\n",
    "    \n",
    "    #crop_image\n",
    "    X_crop = crop_image(X)\n",
    "    print(\"plot crop image\")\n",
    "    plot_image(X_crop,1,num_img)\n",
    "    \n",
    "    #rotated\n",
    "    X_rotated = transform_rotate(X)\n",
    "    print(f\"rotated  nmax: {np.max(X_rotated[0])}, nmin: {np.min(X_rotated[0])}\")\n",
    "    plot_image(X_rotated,1,num_img)\n",
    "    print(\"rotated ->preprocess\")\n",
    "    X_rotated_pp,y= preprocess_dataset(X_rotated)\n",
    "    plot_image(X_rotated_pp,1,num_img)\n",
    "    \n",
    "    # image distortion\n",
    "    X_distortion=transform_projection(X,intensity=0.75)\n",
    "    print(f'distorted nmax: {np.max(X_distortion[0])}, nmin: {np.min(X_distortion[0])}')\n",
    "    plot_image(X_distortion,1,num_img)\n",
    "    print(\"distorted -> preprocess\")\n",
    "    X_dst_pp,y= preprocess_dataset(X_distortion)\n",
    "    plot_image(X_dst_pp,1,num_img)\n",
    "    \n",
    "    #brightness\n",
    "    X_brightness = transform_brightness(X)\n",
    "    print(f\"brightness nmax: {np.max(X_brightness[0])}, nmin: {np.min(X_brightness[0])}\")\n",
    "\n",
    "    plot_image(X_brightness,1,num_img)\n",
    "    print(\"brightness=>pre process\")\n",
    "    X_brightness_pp,y= preprocess_dataset(X_brightness)\n",
    "    plot_image(X_brightness_pp,1,num_img)\n",
    "    \n",
    "#     #test input of transform has (num_img,img_size,img_size,1) dimention\n",
    "#     print(\"test input is gray image\")\n",
    "#     X_rotated1 = transform_rotate(X_dst_pp)\n",
    "#     plot_image(X_rotated1,1,num_img)\n",
    "\n",
    "def plot_compare_transform_data_for_khoaluan(X):\n",
    "    import math\n",
    "    X= _convert_shape_to_4_dementions(X)\n",
    "    num_img = X.shape[0]*6\n",
    "    if (num_img >10):\n",
    "        num_img=10\n",
    "   \n",
    "    #compare between preprocess_img, original image, gray image\n",
    "    print(\"origin image\")\n",
    "    plt.imshow(X[0,:,:,::-1])\n",
    "#     x_ori = plot_image(X,1,num_img)\n",
    "        \n",
    "    #gray\n",
    "#     print(\"gray image \")\n",
    "#     x_gray=[]\n",
    "#     for ind,img in enumerate(X):\n",
    "#         x = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "#         x_gray.append(x)\n",
    "#     x_gray = np.asarray(x_gray)\n",
    "    \n",
    "#     print(f\"x_gray shape:  nmax: {np.max(x_gray[0])}, nmin: {np.min(x_gray[0])}\")\n",
    "#     plot_image(x_gray,1,num_img)\n",
    "    \n",
    "    #rotated\n",
    "    X_rotated = []\n",
    "    for i in range(0,6):\n",
    "        x_rotated = transform_rotate(X)\n",
    "        X_rotated.append(x_rotated)\n",
    "    X_rotated = np.asarray(X_rotated)\n",
    "    print(X_rotated.shape)\n",
    "    \n",
    "    X_rotated = X_rotated.reshape(num_img,32,32,3)\n",
    "    print(X_rotated.shape)\n",
    "    print(f\"rotated  nmax: {np.max(X_rotated[0])}, nmin: {np.min(X_rotated[0])}\")\n",
    "    plot_image(X_rotated,1,num_img)\n",
    "    \n",
    "    # image distortion\n",
    "    X_distortion=[]\n",
    "    for i in range(0,6):\n",
    "        x_dis = transform_projection(X,intensity=0.75)\n",
    "        X_distortion.append(x_dis)\n",
    "    print(f'distorted nmax: {np.max(X_distortion[0])}, nmin: {np.min(X_distortion[0])}')\n",
    "    X_distortion = np.asarray(X_distortion)\n",
    "    X_distortion = X_distortion.reshape(num_img,32,32,3)\n",
    "    plot_image(X_distortion,1,num_img)\n",
    "    \n",
    "    #brightness\n",
    "    X_brightness = []\n",
    "    for i in range(0,6):\n",
    "        x_bri = transform_brightness(X)\n",
    "        X_brightness.append(x_bri)\n",
    "    print(f\"brightness nmax: {np.max(X_brightness[0])}, nmin: {np.min(X_brightness[0])}\")\n",
    "    X_brightness = np.asarray(X_brightness)\n",
    "    X_brightness = X_brightness.reshape(num_img,32,32,3)\n",
    "\n",
    "    plot_image(X_brightness,1,num_img)\n",
    "    \n",
    "        \n",
    "    #crop_image\n",
    "    X_crop = []\n",
    "    for i in range(0,6):\n",
    "        x_crop = crop_image(X)\n",
    "        X_crop.append(x_crop)\n",
    "    print(\"plot crop image\")\n",
    "    X_crop = np.asarray(X_crop)\n",
    "    X_crop = X_crop.reshape(num_img,32,32,3)\n",
    "\n",
    "    plot_image(X_crop,1,num_img)\n",
    "    \n",
    "# #Test\n",
    "# index = np.random.randint(0,39000,size=10,dtype=int)\n",
    "# print(\"indexx: \",index)\n",
    "# X = images[index]\n",
    "# print(\"X.shape: \",X.shape)\n",
    "# plot_image(X,1,9)\n",
    "# plot_compare_transform_data(X)\n",
    "# imgs = preprocess_input_gray_norm(X)\n",
    "# print(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test plot image\n",
    "#readdata\n",
    "def read_data(pickle_fn):\n",
    "    if os.path.isfile(pickle_fn):\n",
    "        data= pickle.load(open(pickle_fn,'rb'))\n",
    "        print(f'done read_dataa from {pickle_fn}')\n",
    "        return data\n",
    "    else:\n",
    "        raise Exception(\"the file data enhancement is not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = read_data(r\"..\\data_enhancement\\data_input_gray_no_crop_full_15_12_2018.p\");\n",
    "# print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data['ims'] \n",
    "# X.shape\n",
    "# index = np.random.randint(0, 20000,size = 20)\n",
    "# plot_image(X[index],3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# d2 = read_data(r\"D:\\Downloads\\mydata_no_crop.p\")\n",
    "# X = d2['ims']\n",
    "# index = np.random.randint(0, 20000,size = 1)\n",
    "# print('index:',index)\n",
    "# # index: 7346, 5343, 11024\n",
    "# for i in range (0,2):\n",
    "#     plot_compare_transform_data_for_khoaluan(X[5343])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def choose_transform_function(func_key):\n",
    "    \"\"\"\n",
    "    #arguments\n",
    "        func_key: the key represent transform function\n",
    "    #return\n",
    "        one of transform function or None \n",
    "    \"\"\"\n",
    "    trans_func={\n",
    "        0:transform_rotate,\n",
    "        1:transform_projection,\n",
    "        2:transform_brightness,\n",
    "        3: crop_image\n",
    "    }\n",
    "    func = trans_func.get(func_key,None)\n",
    "    return func\n",
    "\n",
    "def generate_data(images,labels,ratio=1.3):\n",
    "    \"\"\"\n",
    "    #arguments\n",
    "        param images: data will be increased\n",
    "        param labels: labels of data\n",
    "        param ratio: the rate of data increased, if the highest sample is 100 and ratio = 5,\n",
    "        the data will be around 5*100*num_clases\n",
    "    #return:\n",
    "        images, labels is generated\n",
    "    #how it work:\n",
    "        \n",
    "    \"\"\"\n",
    "    #Count number of occurrences, labels must be 1 demention\n",
    "    inputs_per_class  = np.bincount(labels)\n",
    "    max_inputs = np.max(inputs_per_class) *ratio\n",
    "    \n",
    "    num_classes = len(inputs_per_class)\n",
    "    \n",
    "    new_images =[]\n",
    "    new_labels =[]\n",
    "    \n",
    "    count_fun_key =0;\n",
    "    \n",
    "    #one labels\n",
    "    for index_label in range(num_classes):\n",
    "        random_size_different = np.random.randint(0,100,size = 1)\n",
    "        input_ratio = math.ceil((max_inputs - inputs_per_class[index_label])/inputs_per_class[index_label])\n",
    "        input_different = max_inputs - inputs_per_class[index_label] + random_size_different\n",
    "        input_different = input_different[0].astype(int)\n",
    "        print(f\"generating class: {index_label}, ratio: {input_ratio}, \\\n",
    "        current: {inputs_per_class[index_label]}, max samples: {max_inputs}\\\n",
    "        input_different: {input_different}\")\n",
    "        \n",
    "        if input_ratio < 1:\n",
    "            continue\n",
    "        if input_different < 50: \n",
    "            continue\n",
    "            \n",
    "        index_input = np.where(labels==index_label)[0]\n",
    "        len_index_input = np.size(index_input)\n",
    "        \n",
    "        index_of_index_input = np.random.randint(0,len_index_input,size = input_different)\n",
    "        index_input_generate = index_input[index_of_index_input]\n",
    "        \n",
    "        index_function_trasform = np.random.randint(0,4, size=input_different)\n",
    "        print(type(input_different))\n",
    "        for i in range(0,input_different):\n",
    "            if i%100 == 0:\n",
    "                print('generate i: ',i)\n",
    "            img = images[index_input_generate]\n",
    "            func_key = index_function_trasform[i]\n",
    "            trans_func = choose_transform_function(func_key)\n",
    "            img_trans = trans_func(img)\n",
    "            new_images.extend(img_trans)\n",
    "            new_labels.append(index_label)\n",
    "\n",
    "        \n",
    "        #one img\n",
    "#         for img in images[index_input]:\n",
    "#             #the key func: [0:3)\n",
    "#             trans_func_keys = np.random.randint(low=0,high=4,size=input_ratio)\n",
    "# #             print(\"trans_func_keys: \",trans_func_keys)\n",
    "#             for func_key in trans_func_keys:\n",
    "#                 trans_func = choose_transform_function(func_key)\n",
    "# #                 print(f\"count funtion key: {count_fun_key}; trans_func: {trans_func.__name__}\")\n",
    "#                 count_fun_key +=1\n",
    "#                 if trans_func is None:\n",
    "#                     raise Exception(\"key of transform function is error\")\n",
    "#                 img_trans = trans_func(img)\n",
    "#                 new_images.extend(img_trans)\n",
    "#                 new_labels.append(index_label)\n",
    "    \n",
    "    new_images = np.asarray(new_images)\n",
    "    new_labels = np.asarray(new_labels)\n",
    "    print(f\"generate data: new_images shape {new_images.shape}, new_labels shape {new_labels.shape}\")\n",
    "    return new_images,new_labels\n",
    "\n",
    "def save_data_enhancement(ims,lbs, pickle_fn):\n",
    "    \"\"\"\n",
    "    #argument:\n",
    "        ims: images\n",
    "        lbs: labels\n",
    "        file_name: file name  of data is saved\n",
    "    \"\"\"\n",
    "    if not os.path.exists(os.path.dirname(pickle_fn)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(pickle_fn))\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    \n",
    "    ims = np.asarray(ims)\n",
    "    lbs = np.asarray(lbs)\n",
    "    data ={'ims':ims,'lbs':lbs}\n",
    "    with open(pickle_fn,'wb') as f:\n",
    "        check =pickle.dump(data,f)\n",
    "    print(f'done save_data into {pickle_fn}')\n",
    "        \n",
    "def read_data_enhancement(pickle_fn):\n",
    "    \"\"\"\n",
    "    #argument: \n",
    "        file_name: file's name is loaded\n",
    "    #return: \n",
    "        images, labels\n",
    "    \"\"\"\n",
    "    if os.path.isfile(pickle_fn):\n",
    "        data= pickle.load(open(pickle_fn,'rb'))\n",
    "        print(f'done read_dataa from {pickle_fn}')\n",
    "        return data\n",
    "    else:\n",
    "        raise Exception(\"the file data enhancement is not found\")\n",
    "def concatenate_data(data_raw, data_generate):\n",
    "    \"\"\"\n",
    "    #argument: \n",
    "        data_raw: data raw\n",
    "        data_generate: data is generated\n",
    "    #return\n",
    "        imgs_raw, data_generate are concated\\\n",
    "        \n",
    "    uses for label and imgs\n",
    "    \"\"\"\n",
    "#     if not data_raw[].shape[1:4]==data_generate[].shape[1:4]:\n",
    "#         raise Exception(\"the shape of data_raw,data_generate are not same\")\n",
    "     \n",
    "    #shape ims: (num_img,img_size,img_size,channel) => concatenate with axis =0\n",
    "    data = np.append(data_raw,data_generate,axis=0)\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done read_dataa from ..\\data_pickle\\mydata_no_crop.p\n",
      "dict_keys(['ims', 'lbs', 'num_class', 'lbs_name'])\n",
      "(39209, 32, 32, 3)\n",
      "(39209,)\n"
     ]
    }
   ],
   "source": [
    "data = read_data(r\"..\\data_pickle\\mydata_no_crop.p\");\n",
    "print(data.keys())\n",
    "print(data['ims'].shape)\n",
    "print(data['lbs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating class: 0, ratio: 12,         current: 210, max samples: 2700.0        input_different: 2492\n",
      "<class 'numpy.int32'>\n",
      "generate i:  0\n",
      "generate i:  100\n",
      "generate i:  200\n",
      "generate i:  300\n",
      "generate i:  400\n",
      "generate i:  500\n",
      "generate i:  600\n",
      "generate i:  700\n",
      "generate i:  800\n",
      "generate i:  900\n",
      "generate i:  1000\n",
      "generate i:  1100\n",
      "generate i:  1200\n",
      "generate i:  1300\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-da41038d2747>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# file_name_data = \"crop\\data_crop_color.p\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnew_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ims'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lbs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'new_images {new_images}, new_labels {new_labels}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c21560469824>\u001b[0m in \u001b[0;36mgenerate_data\u001b[1;34m(images, labels, ratio)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfunc_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_function_trasform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mtrans_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchoose_transform_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mimg_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrans_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[0mnew_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_trans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mnew_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1fbd2c5088f8>\u001b[0m in \u001b[0;36mtransform_rotate\u001b[1;34m(X, intensity)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mX_rotate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mX_rotate\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_rotate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX_rotate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Hoang\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#generate and save data\n",
    "file_name_data = r\"../data_pickle/new_data_gen_2012.p\"\n",
    "# file_name_data = \"crop\\data_crop_color.p\"\n",
    "\n",
    "new_images,new_labels = generate_data(data['ims'],data['lbs'],ratio=1.2)\n",
    "print(f'new_images {new_images}, new_labels {new_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_enhancement(new_images,new_labels,file_name=file_name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_data_generate \n",
    "data_generate = read_data_enhancement(file_name=file_name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data_generate['ims'].shape)\n",
    "print(data_generate['lbs'].shape)\n",
    "# print(images.shape)\n",
    "#concate data\n",
    "x_generate =data_generate['ims']\n",
    "y_generate =data_generate['lbs']\n",
    "print(\"max pixel: \",np.max(x_generate))\n",
    "X = concatenate_data(images,x_generate)\n",
    "y=concatenate_data(labels,y_generate)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "file_name_full = \"full\\data_3009.p\"\n",
    "save_data_enhancement(ims=X,lbs=y,file_name=file_name_full)\n",
    "\n",
    "y=convert_onehot_numpy(y,num_classes=43)\n",
    "print(y.shape)\n",
    "# X,y =preprocess_dataset(X,y,is_shuffle=True)\n",
    "#shuffle \n",
    "\n",
    "X,y = shuffle(X,y)\n",
    "print(\"done shuffle\")\n",
    "X = preprocess_input_gray_norm(X)\n",
    "file_name_full = \"full\\data_2012_processed_gray_norm.p\"\n",
    "save_data_enhancement(ims=X,lbs=y,file_name=file_name_full)\n",
    "\n",
    "print(X.shape)\n",
    "print(\"done preprocess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(X))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "IMG_SIZE=32\n",
    "NUM_CLASSES=43\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=( IMG_SIZE, IMG_SIZE,1),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95612 samples, validate on 23904 samples\n",
      "Epoch 1/30\n",
      "95612/95612 [==============================] - 57s 597us/step - loss: 1.1231 - acc: 0.6855 - val_loss: 0.1919 - val_acc: 0.9453\n",
      "Epoch 2/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.2604 - acc: 0.9244 - val_loss: 0.0939 - val_acc: 0.9711\n",
      "Epoch 3/30\n",
      "95612/95612 [==============================] - 53s 557us/step - loss: 0.1844 - acc: 0.9457 - val_loss: 0.0663 - val_acc: 0.9817\n",
      "Epoch 4/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1486 - acc: 0.9576 - val_loss: 0.0667 - val_acc: 0.9805\n",
      "Epoch 5/30\n",
      "95612/95612 [==============================] - 53s 557us/step - loss: 0.1341 - acc: 0.9616 - val_loss: 0.0548 - val_acc: 0.9844\n",
      "Epoch 6/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1246 - acc: 0.9651 - val_loss: 0.0631 - val_acc: 0.9817\n",
      "Epoch 7/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1172 - acc: 0.9672 - val_loss: 0.0591 - val_acc: 0.9840\n",
      "Epoch 8/30\n",
      "95612/95612 [==============================] - 53s 557us/step - loss: 0.1198 - acc: 0.9670 - val_loss: 0.0525 - val_acc: 0.9851\n",
      "Epoch 9/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1122 - acc: 0.9696 - val_loss: 0.0508 - val_acc: 0.9859\n",
      "Epoch 10/30\n",
      "95612/95612 [==============================] - 53s 559us/step - loss: 0.1097 - acc: 0.9704 - val_loss: 0.0615 - val_acc: 0.9839\n",
      "Epoch 11/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1127 - acc: 0.9705 - val_loss: 0.0446 - val_acc: 0.9872\n",
      "Epoch 12/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1114 - acc: 0.9716 - val_loss: 0.0473 - val_acc: 0.9876\n",
      "Epoch 13/30\n",
      "95612/95612 [==============================] - 53s 559us/step - loss: 0.1126 - acc: 0.9709 - val_loss: 0.0492 - val_acc: 0.9871\n",
      "Epoch 14/30\n",
      "95612/95612 [==============================] - 53s 559us/step - loss: 0.1143 - acc: 0.9711 - val_loss: 0.0560 - val_acc: 0.9849\n",
      "Epoch 15/30\n",
      "95612/95612 [==============================] - 53s 559us/step - loss: 0.1116 - acc: 0.9725 - val_loss: 0.0449 - val_acc: 0.9882\n",
      "Epoch 16/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1133 - acc: 0.9716 - val_loss: 0.0500 - val_acc: 0.9873\n",
      "Epoch 17/30\n",
      "95612/95612 [==============================] - 53s 559us/step - loss: 0.1144 - acc: 0.9726 - val_loss: 0.0419 - val_acc: 0.9890\n",
      "Epoch 18/30\n",
      "95612/95612 [==============================] - 53s 559us/step - loss: 0.1074 - acc: 0.9741 - val_loss: 0.0462 - val_acc: 0.9881\n",
      "Epoch 19/30\n",
      "95612/95612 [==============================] - 53s 559us/step - loss: 0.1178 - acc: 0.9719 - val_loss: 0.0443 - val_acc: 0.9879\n",
      "Epoch 20/30\n",
      "95612/95612 [==============================] - 53s 559us/step - loss: 0.1141 - acc: 0.9724 - val_loss: 0.0521 - val_acc: 0.9871\n",
      "Epoch 21/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1199 - acc: 0.9720 - val_loss: 0.0557 - val_acc: 0.9862\n",
      "Epoch 22/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1167 - acc: 0.9735 - val_loss: 0.0451 - val_acc: 0.9890\n",
      "Epoch 23/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1387 - acc: 0.9706 - val_loss: 0.0561 - val_acc: 0.9859\n",
      "Epoch 24/30\n",
      "95612/95612 [==============================] - 53s 557us/step - loss: 0.1350 - acc: 0.9711 - val_loss: 0.0579 - val_acc: 0.9860\n",
      "Epoch 25/30\n",
      "95612/95612 [==============================] - 53s 557us/step - loss: 0.1359 - acc: 0.9713 - val_loss: 0.0662 - val_acc: 0.9845\n",
      "Epoch 26/30\n",
      "95612/95612 [==============================] - 53s 558us/step - loss: 0.1354 - acc: 0.9713 - val_loss: 0.0638 - val_acc: 0.9845\n",
      "Epoch 27/30\n",
      "95612/95612 [==============================] - 53s 554us/step - loss: 0.1381 - acc: 0.9708 - val_loss: 0.0550 - val_acc: 0.9877\n",
      "Epoch 28/30\n",
      "95612/95612 [==============================] - 53s 555us/step - loss: 0.1518 - acc: 0.9701 - val_loss: 0.0865 - val_acc: 0.9818\n",
      "Epoch 29/30\n",
      "95612/95612 [==============================] - 53s 555us/step - loss: 0.1412 - acc: 0.9706 - val_loss: 0.0551 - val_acc: 0.9883\n",
      "Epoch 30/30\n",
      "95612/95612 [==============================] - 53s 553us/step - loss: 0.1554 - acc: 0.9680 - val_loss: 0.0538 - val_acc: 0.9869\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "model = cnn_model()\n",
    "lr=0.001\n",
    "adam = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# def lr_schedule(epoch):\n",
    "#     return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "model.fit(X, y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,validation_split=0.2,\n",
    "          callbacks=[ModelCheckpoint('..\\model\\model_gray_no_crop.h5', save_best_only=True)]\n",
    "          )\n",
    "\n",
    "model.save(\"my_model_gray_no_crop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Filename', 'Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2', 'ClassId']\n",
      "(12630,)\n",
      "(12630, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "test = pd.read_csv(r\"..\\data\\test\\GTSRB\\GT-final_test.csv\", sep=';')\n",
    "\n",
    "# Load test dataset\n",
    "X_test = []\n",
    "y_test = []\n",
    "i = 0\n",
    "print(list(test))\n",
    "# print(list(test['Filename']))\n",
    "# print(list(test['ClassId']))\n",
    "\n",
    "for file_name, class_id in zip(list(test['Filename']), list(test['ClassId'])):\n",
    "    img_path = os.path.join(r'..\\data\\test\\GTSRB', file_name)\n",
    "#     print(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img,(32,32))\n",
    "    red_channel =img[:,:,0]\n",
    "    green_channel = img[:,:,1]\n",
    "    blue_channel = img[:,:,2]\n",
    "\n",
    "    #convert image to gray by red, greeen, blue channel\n",
    "    gray_img = 0.2989 * red_channel + 0.5870 * green_channel + 0.1140 * blue_channel\n",
    "\n",
    "    if (np.max(gray_img)>1):\n",
    "        gray_img = gray_img/255.\n",
    "  \n",
    "    X_test.append(gray_img)\n",
    "    y_test.append(class_id)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test=X_test.reshape(X_test.shape +(1,))\n",
    "y_test = np.array(y_test)\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16  1 38 ...  6  7 10]\n",
      "42\n",
      "Test accuracy = 0.9770387965162312\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#predict\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred)\n",
    "print(np.max(y_pred))\n",
    "acc = np.sum(y_pred == y_test) / np.size(y_pred)\n",
    "print(\"Test accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model(\"..\\my_model.h5\")\n",
    "# print(model.get_weights())\n",
    "# print(model.summary())\n",
    "# predict and evaluate\n",
    "# y_pred = model.predict_classes(X_test[11743].reshape(-1,32,32,3))\n",
    "# # print(y_pred.shape)\n",
    "# print(y_pred)\n",
    "# print(np.max(y_pred))\n",
    "# acc = np.sum(y_pred == y_test) / np.size(y_pred)\n",
    "# print(\"Test accuracy = {}\".format(acc))\n",
    "\n",
    "# print(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*32*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if 4%2 == 0:\n",
    "    print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
